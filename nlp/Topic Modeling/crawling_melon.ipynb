{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 _ 1\n",
      "2015 _ 2\n",
      "2015 _ 3\n",
      "2015 _ 4\n",
      "2015 _ 5\n",
      "2015 _ 6\n",
      "2015 _ 7\n",
      "2015 _ 8\n",
      "2015 _ 9\n",
      "2015 _ 10\n",
      "2015 _ 11\n",
      "2015 _ 12\n",
      "2015 _ 13\n",
      "2015 _ 14\n",
      "2015 _ 15\n",
      "2015 _ 16\n",
      "2015 _ 17\n",
      "2015 _ 18\n",
      "2015 _ 19\n",
      "2015 _ 20\n",
      "2015 _ 21\n",
      "2015 _ 22\n",
      "2015 _ 23\n",
      "2015 _ 24\n",
      "2015 _ 25\n",
      "2015 _ 26\n",
      "2015 _ 27\n",
      "2015 _ 28\n",
      "2015 _ 29\n",
      "2015 _ 30\n",
      "2015 _ 31\n",
      "2015 _ 32\n",
      "2015 _ 33\n",
      "2015 _ 34\n",
      "2015 _ 35\n",
      "2015 _ 36\n",
      "2015 _ 37\n",
      "2015 _ 38\n",
      "2015 _ 39\n",
      "2015 _ 40\n",
      "2015 _ 41\n",
      "2015 _ 42\n",
      "2015 _ 43\n",
      "2015 _ 44\n",
      "2015 _ 45\n",
      "2015 _ 46\n",
      "2015 _ 47\n",
      "2015 _ 48\n",
      "2015 _ 49\n",
      "2015 _ 50\n",
      "2016 _ 1\n",
      "2016 _ 2\n",
      "2016 _ 3\n",
      "2016 _ 4\n",
      "2016 _ 5\n",
      "2016 _ 6\n",
      "2016 _ 7\n",
      "2016 _ 8\n",
      "2016 _ 9\n",
      "2016 _ 10\n",
      "2016 _ 11\n",
      "2016 _ 12\n",
      "2016 _ 13\n",
      "2016 _ 14\n",
      "2016 _ 15\n",
      "2016 _ 16\n",
      "2016 _ 17\n",
      "2016 _ 18\n",
      "2016 _ 19\n",
      "2016 _ 20\n",
      "2016 _ 21\n",
      "2016 _ 22\n",
      "2016 _ 23\n",
      "2016 _ 24\n",
      "2016 _ 25\n",
      "2016 _ 26\n",
      "2016 _ 27\n",
      "2016 _ 28\n",
      "2016 _ 29\n",
      "2016 _ 30\n",
      "2016 _ 31\n",
      "2016 _ 32\n",
      "2016 _ 33\n",
      "2016 _ 34\n",
      "2016 _ 35\n",
      "2016 _ 36\n",
      "2016 _ 37\n",
      "2016 _ 38\n",
      "2016 _ 39\n",
      "2016 _ 40\n",
      "2016 _ 41\n",
      "2016 _ 42\n",
      "2016 _ 43\n",
      "2016 _ 44\n",
      "2016 _ 45\n",
      "2016 _ 46\n",
      "2016 _ 47\n",
      "2016 _ 48\n",
      "2016 _ 49\n",
      "2016 _ 50\n",
      "2017 _ 1\n",
      "2017 _ 2\n",
      "2017 _ 3\n",
      "2017 _ 4\n",
      "2017 _ 5\n",
      "2017 _ 6\n",
      "2017 _ 7\n",
      "2017 _ 8\n",
      "2017 _ 9\n",
      "2017 _ 10\n",
      "2017 _ 11\n",
      "2017 _ 12\n",
      "2017 _ 13\n",
      "2017 _ 14\n",
      "2017 _ 15\n",
      "2017 _ 16\n",
      "2017 _ 17\n",
      "2017 _ 18\n",
      "2017 _ 19\n",
      "2017 _ 20\n",
      "2017 _ 21\n",
      "2017 _ 22\n",
      "2017 _ 23\n",
      "2017 _ 24\n",
      "2017 _ 25\n",
      "2017 _ 26\n",
      "2017 _ 27\n",
      "2017 _ 28\n",
      "2017 _ 29\n",
      "2017 _ 30\n",
      "2017 _ 31\n",
      "2017 _ 32\n",
      "2017 _ 33\n",
      "2017 _ 34\n",
      "2017 _ 35\n",
      "2017 _ 36\n",
      "2017 _ 37\n",
      "2017 _ 38\n",
      "2017 _ 39\n",
      "2017 _ 40\n",
      "2017 _ 41\n",
      "2017 _ 42\n",
      "2017 _ 43\n",
      "2017 _ 44\n",
      "2017 _ 45\n",
      "2017 _ 46\n",
      "2017 _ 47\n",
      "2017 _ 48\n",
      "2017 _ 49\n",
      "2017 _ 50\n",
      "2018 _ 1\n",
      "2018 _ 2\n",
      "2018 _ 3\n",
      "2018 _ 4\n",
      "2018 _ 5\n",
      "2018 _ 6\n",
      "2018 _ 7\n",
      "2018 _ 8\n",
      "2018 _ 9\n",
      "2018 _ 10\n",
      "2018 _ 11\n",
      "2018 _ 12\n",
      "2018 _ 13\n",
      "2018 _ 14\n",
      "2018 _ 15\n",
      "2018 _ 16\n",
      "2018 _ 17\n",
      "2018 _ 18\n",
      "2018 _ 19\n",
      "2018 _ 20\n",
      "2018 _ 21\n",
      "2018 _ 22\n",
      "2018 _ 23\n",
      "2018 _ 24\n",
      "2018 _ 25\n",
      "2018 _ 26\n",
      "2018 _ 27\n",
      "2018 _ 28\n",
      "2018 _ 29\n",
      "2018 _ 30\n",
      "2018 _ 31\n",
      "2018 _ 32\n",
      "2018 _ 33\n",
      "2018 _ 34\n",
      "2018 _ 35\n",
      "2018 _ 36\n",
      "2018 _ 37\n",
      "2018 _ 38\n",
      "2018 _ 39\n",
      "2018 _ 40\n",
      "2018 _ 41\n",
      "2018 _ 42\n",
      "2018 _ 43\n",
      "2018 _ 44\n",
      "2018 _ 45\n",
      "2018 _ 46\n",
      "2018 _ 47\n",
      "2018 _ 48\n",
      "2018 _ 49\n",
      "2018 _ 50\n",
      "2019 _ 1\n",
      "2019 _ 2\n",
      "2019 _ 3\n",
      "2019 _ 4\n",
      "2019 _ 5\n",
      "2019 _ 6\n",
      "2019 _ 7\n",
      "2019 _ 8\n",
      "2019 _ 9\n",
      "2019 _ 10\n",
      "2019 _ 11\n",
      "2019 _ 12\n",
      "2019 _ 13\n",
      "2019 _ 14\n",
      "2019 _ 15\n",
      "2019 _ 16\n",
      "2019 _ 17\n",
      "2019 _ 18\n",
      "2019 _ 19\n",
      "2019 _ 20\n",
      "2019 _ 21\n",
      "2019 _ 22\n",
      "2019 _ 23\n",
      "2019 _ 24\n",
      "2019 _ 25\n",
      "2019 _ 26\n",
      "2019 _ 27\n",
      "2019 _ 28\n",
      "2019 _ 29\n",
      "2019 _ 30\n",
      "2019 _ 31\n",
      "2019 _ 32\n",
      "2019 _ 33\n",
      "2019 _ 34\n",
      "2019 _ 35\n",
      "2019 _ 36\n",
      "2019 _ 37\n",
      "2019 _ 38\n",
      "2019 _ 39\n",
      "2019 _ 40\n",
      "2019 _ 41\n",
      "2019 _ 42\n",
      "2019 _ 43\n",
      "2019 _ 44\n",
      "2019 _ 45\n",
      "2019 _ 46\n",
      "2019 _ 47\n",
      "2019 _ 48\n",
      "2019 _ 49\n",
      "2019 _ 50\n",
      "2020 _ 1\n",
      "2020 _ 2\n",
      "2020 _ 3\n",
      "2020 _ 4\n",
      "2020 _ 5\n",
      "2020 _ 6\n",
      "2020 _ 7\n",
      "2020 _ 8\n",
      "2020 _ 9\n",
      "2020 _ 10\n",
      "2020 _ 11\n",
      "2020 _ 12\n",
      "2020 _ 13\n",
      "2020 _ 14\n",
      "2020 _ 15\n",
      "2020 _ 16\n",
      "2020 _ 17\n",
      "2020 _ 18\n",
      "2020 _ 19\n",
      "2020 _ 20\n",
      "2020 _ 21\n",
      "2020 _ 22\n",
      "2020 _ 23\n",
      "2020 _ 24\n",
      "2020 _ 25\n",
      "2020 _ 26\n",
      "2020 _ 27\n",
      "2020 _ 28\n",
      "2020 _ 29\n",
      "2020 _ 30\n",
      "2020 _ 31\n",
      "2020 _ 32\n",
      "2020 _ 33\n",
      "2020 _ 34\n",
      "2020 _ 35\n",
      "2020 _ 36\n",
      "2020 _ 37\n",
      "2020 _ 38\n",
      "2020 _ 39\n",
      "2020 _ 40\n",
      "2020 _ 41\n",
      "2020 _ 42\n",
      "2020 _ 43\n",
      "2020 _ 44\n",
      "2020 _ 45\n",
      "2020 _ 46\n",
      "2020 _ 47\n",
      "2020 _ 48\n",
      "2020 _ 49\n",
      "2020 _ 50\n",
      "2021 _ 1\n",
      "2021 _ 2\n",
      "2021 _ 3\n",
      "2021 _ 4\n",
      "2021 _ 5\n",
      "2021 _ 6\n",
      "2021 _ 7\n",
      "2021 _ 8\n",
      "2021 _ 9\n",
      "2021 _ 10\n",
      "2021 _ 11\n",
      "2021 _ 12\n",
      "2021 _ 13\n",
      "2021 _ 14\n",
      "2021 _ 15\n",
      "2021 _ 16\n",
      "2021 _ 17\n",
      "2021 _ 18\n",
      "2021 _ 19\n",
      "2021 _ 20\n",
      "2021 _ 21\n",
      "2021 _ 22\n",
      "2021 _ 23\n",
      "2021 _ 24\n",
      "2021 _ 25\n",
      "2021 _ 26\n",
      "2021 _ 27\n",
      "2021 _ 28\n",
      "2021 _ 29\n",
      "2021 _ 30\n",
      "2021 _ 31\n",
      "2021 _ 32\n",
      "2021 _ 33\n",
      "2021 _ 34\n",
      "2021 _ 35\n",
      "2021 _ 36\n",
      "2021 _ 37\n",
      "2021 _ 38\n",
      "2021 _ 39\n",
      "2021 _ 40\n",
      "2021 _ 41\n",
      "2021 _ 42\n",
      "2021 _ 43\n",
      "2021 _ 44\n",
      "2021 _ 45\n",
      "2021 _ 46\n",
      "2021 _ 47\n",
      "2021 _ 48\n",
      "2021 _ 49\n",
      "2021 _ 50\n",
      "2022 _ 1\n",
      "2022 _ 2\n",
      "2022 _ 3\n",
      "2022 _ 4\n",
      "2022 _ 5\n",
      "2022 _ 6\n",
      "2022 _ 7\n",
      "2022 _ 8\n",
      "2022 _ 9\n",
      "2022 _ 10\n",
      "2022 _ 11\n",
      "2022 _ 12\n",
      "2022 _ 13\n",
      "2022 _ 14\n",
      "2022 _ 15\n",
      "2022 _ 16\n",
      "2022 _ 17\n",
      "2022 _ 18\n",
      "2022 _ 19\n",
      "2022 _ 20\n",
      "2022 _ 21\n",
      "2022 _ 22\n",
      "2022 _ 23\n",
      "2022 _ 24\n",
      "2022 _ 25\n",
      "2022 _ 26\n",
      "2022 _ 27\n",
      "2022 _ 28\n",
      "2022 _ 29\n",
      "2022 _ 30\n",
      "2022 _ 31\n",
      "2022 _ 32\n",
      "2022 _ 33\n",
      "2022 _ 34\n",
      "2022 _ 35\n",
      "2022 _ 36\n",
      "2022 _ 37\n",
      "2022 _ 38\n",
      "2022 _ 39\n",
      "2022 _ 40\n",
      "2022 _ 41\n",
      "2022 _ 42\n",
      "2022 _ 43\n",
      "2022 _ 44\n",
      "2022 _ 45\n",
      "2022 _ 46\n",
      "2022 _ 47\n",
      "2022 _ 48\n",
      "2022 _ 49\n",
      "2022 _ 50\n",
      "2023 _ 1\n",
      "2023 _ 2\n",
      "2023 _ 3\n",
      "2023 _ 4\n",
      "2023 _ 5\n",
      "2023 _ 6\n",
      "2023 _ 7\n",
      "2023 _ 8\n",
      "2023 _ 9\n",
      "2023 _ 10\n",
      "2023 _ 11\n",
      "2023 _ 12\n",
      "2023 _ 13\n",
      "2023 _ 14\n",
      "2023 _ 15\n",
      "2023 _ 16\n",
      "2023 _ 17\n",
      "2023 _ 18\n",
      "2023 _ 19\n",
      "2023 _ 20\n",
      "2023 _ 21\n",
      "2023 _ 22\n",
      "2023 _ 23\n",
      "2023 _ 24\n",
      "2023 _ 25\n",
      "2023 _ 26\n",
      "2023 _ 27\n",
      "2023 _ 28\n",
      "2023 _ 29\n",
      "2023 _ 30\n",
      "2023 _ 31\n",
      "2023 _ 32\n",
      "2023 _ 33\n",
      "2023 _ 34\n",
      "2023 _ 35\n",
      "2023 _ 36\n",
      "2023 _ 37\n",
      "2023 _ 38\n",
      "2023 _ 39\n",
      "2023 _ 40\n",
      "2023 _ 41\n",
      "2023 _ 42\n",
      "2023 _ 43\n",
      "2023 _ 44\n",
      "2023 _ 45\n",
      "2023 _ 46\n",
      "2023 _ 47\n",
      "2023 _ 48\n",
      "2023 _ 49\n",
      "2023 _ 50\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "def collect_melon(chartdate):\n",
    "    headers = {\n",
    "        'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                       '(KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'),\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    age_url = \"https://www.melon.com/chart/age/list.htm\"\n",
    "    params = {\n",
    "        'idx': '1',\n",
    "        'chartType': 'YE',     # 년도별로\n",
    "        'chartGenre': 'KPOP',  # 한국가요\n",
    "        'chartDate': chartdate,   # 검색연도\n",
    "        'moved': 'Y',\n",
    "    }\n",
    "    response = requests.get(age_url, params=params, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Request failed with status code {response.status_code}. Potentially blocked.\")\n",
    "        return\n",
    "    if \"Access Denied\" in response.text or \"blocked\" in response.text:\n",
    "        print(\"Access appears to be blocked.\")\n",
    "        return\n",
    "    response = requests.get(age_url, params=params, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    song_list = soup.select('.lst50')\n",
    "\n",
    "    #데이터 담을 리스트 생성\n",
    "    data = []\n",
    "    # 엑셀 파일을 생성할 경로 설정\n",
    "    excel_file_path = f\"./{chartdate}.xlsx\"  \n",
    "    for i, meta in enumerate(song_list, 1):\n",
    "        # 순위, 제목\n",
    "        rank = i\n",
    "        print(params['chartDate'], \"_\", rank)\n",
    "        try:\n",
    "            title = meta.select('a[href*=playSong]')[0].text\n",
    "        except:\n",
    "            title = meta.select('.wrap_song_info .ellipsis')[0].text\n",
    "        title = title.strip()\n",
    "\n",
    "        # 노래 데이터 URL의 HTML 추출\n",
    "        song_id_html = str(meta.select('a[onclick*=SongDetail]'))\n",
    "        matched = re.search(r\"\\'(\\d+)\\'\", song_id_html)\n",
    "        song_id = matched.group(1)\n",
    "        front_url = 'https://www.melon.com/song/detail.htm?songId='\n",
    "        song_url = front_url + song_id\n",
    "\n",
    "        response = requests.get(song_url, params=params, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Request failed with status code {response.status_code}. Potentially blocked.\")\n",
    "            return\n",
    "        if \"Access Denied\" in response.text or \"blocked\" in response.text:\n",
    "            print(\"Access appears to be blocked.\")\n",
    "            return\n",
    "        \n",
    "        # 가수, 장르 등 노래 세부 정보 추출\n",
    "        response = requests.get(song_url, params=params, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        singer_html = soup.select('.wrap_info .artist a')\n",
    "\n",
    "        # 가수\n",
    "        singer_s = []\n",
    "        if len(singer_html) != 0:\n",
    "            for html in singer_html:\n",
    "                singer_s.append(html['title'])\n",
    "        else:\n",
    "            # URL 없는 Various Artists용\n",
    "            singer_html = str(soup.select('.wrap_info .artist')[0])\n",
    "            singer_html = singer_html.replace('\\t', '').replace('\\r', '').split('\\n')\n",
    "            singer_html = ''.join(singer_html)\n",
    "            matched = re.search(r\">(.*)<\", singer_html)\n",
    "            singer_s.append(matched.group(1))\n",
    "\n",
    "        # 가수가 여러명일 때 하나의 string으로 표현\n",
    "        singer_s = ', '.join(singer_s)\n",
    "\n",
    "        # 장르\n",
    "        try:\n",
    "            song_genre_html = str(soup.select('.list dd')[2])\n",
    "            matched = re.search(r\">(.*)<\", song_genre_html)\n",
    "            song_genre = matched.group(1)\n",
    "        except:\n",
    "            song_genre = \"없음\"\n",
    "\n",
    "        # 가사 추출\n",
    "        try:\n",
    "            lyric_html = str(soup.select('.section_lyric .wrap_lyric .lyric')[0])\n",
    "            lyric_html = lyric_html.replace('\\t', '').replace('\\r', '').split('\\n')\n",
    "            lyric_html = ''.join(lyric_html)\n",
    "\n",
    "            matched = re.search(r\"-->(.*)<br/>\", lyric_html)\n",
    "            lyric = matched.group(1).strip()\n",
    "            lyric = lyric.replace('<br/>', '\\n')\n",
    "\n",
    "            # 가사 앞뒤 빈칸 제거\n",
    "            lyric_list = []\n",
    "            for line in lyric.split('\\n'):\n",
    "                lyric_list.append(line.strip())\n",
    "            lyric = ('\\n').join(lyric_list)\n",
    "\n",
    "        except:\n",
    "            lyric = \"없음\"\n",
    "\n",
    "        # 데이터 리스트에 추가\n",
    "        data.append([params['chartDate'], singer_s, title, song_genre, lyric,song_url])\n",
    "\n",
    "        # IP 차단 방지용\n",
    "        sleep(1)\n",
    "\n",
    "    # pandas DataFrame 생성 및 Excel 파일로 저장\n",
    "    df = pd.DataFrame(data, columns=['Year', 'Singer', 'Title', 'Genre', 'Lyric','URL'])\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "for i in range(2015,2024): #원하는 년도 설정(23년까지)\n",
    "    collect_melon(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# 파일 경로 설정 (확장자를 가진 모든 엑셀 파일 불러오기)\n",
    "file_paths = glob.glob(\"C:/Users/lsc/Desktop/melon/raw1/*.xlsx\")\n",
    "\n",
    "# 모든 파일을 데이터프레임으로 읽어서 리스트에 저장\n",
    "dfs = [pd.read_excel(file) for file in file_paths]\n",
    "\n",
    "# 모든 데이터프레임을 하나로 합치기\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 합쳐진 데이터를 하나의 엑셀 파일로 저장\n",
    "merged_df.to_excel(\"merged_file.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980,\n",
       "        1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991,\n",
       "        1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,\n",
       "        2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013,\n",
       "        2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023],\n",
       "       dtype=int64),\n",
       " array([26, 32, 44, 39, 41, 38, 39, 35, 48, 43, 30, 40, 39, 27, 50, 50, 50,\n",
       "        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "        50, 50, 50], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(merged_df['Year'],return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
